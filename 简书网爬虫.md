## 第八章：多进程加载 简书网爬虫遇到的问题

### 1.爬like, comment等爬不到，返回的一直是[]
源代码段：
```html
    <div class="meta">
        <a class="collection-tag" target="_blank" href="/c/fcd7a62be697">故事</a>
        
        <a target="_blank" href="/p/0d4be61c551c">
            <i class="iconfont ic-list-read"></i> 129
        </a>        
        
        <a target="_blank" href="/p/0d4be61c551c#comments">
            <i class="iconfont ic-list-comments"></i> 41
        </a>  
        
        <span>
            <i class="iconfont ic-list-like"></i> 47
        </span>
    </div>
```
>markdown内嵌html还不想让其被parse的时候参考本文档内容。

我的写法是：
```python
like = c.xpath('div[@class="meta"]/a[2]/i/text()')
```
正确写法是：
```python
like = c.xpath('div[@class="meta"]/a[2]/text()')[1]
```
这是因为i是icon不是文字内容，是icon，观察不细致。另外注意index是[1]，这是因为[0]是icon标签。


### 2. 多进程执行后， 提示Runtime Error
```python
RuntimeError: 
            Attempt to start a new process before the current process
            has finished its bootstrapping phase.

            This probably means that you are on Windows and you have
            forgotten to use the proper idiom in the main module:

                if __name__ == '__main__':
                    freeze_support()
                    ...
```
程序文件里需要 if __name__ == '__main__', 加上后问题消失。


### 3. url与预期不符，返回的是'h'而不是url
```
Traceback (most recent call last):
  File "C:/Users/Li Zhenhan/PycharmProjects/try1/JianShu.py", line 57, in <module>
    pool.map(mulFunc,urls)
  File "C:\Python27\lib\multiprocessing\pool.py", line 251, in map
    return self.map_async(func, iterable, chunksize).get()
  File "C:\Python27\lib\multiprocessing\pool.py", line 567, in get
    raise self._value
https://www.jianshu.com/?page=50
Started
requests.exceptions.MissingSchema: Invalid URL 'h': No schema supplied. Perhaps you meant http://h?
```
Ok, 这个问题解决了，多进程函数没搞明白，函数传递单一url，多进程传递urls
```python
def mulFunc(url):
   ...

if __name__ == '__main__':
    print(urls)
    pool = Pool(processes=4)
    pool.map(mulFunc,urls)
```
### 4. 数据库内容无变化
collection的内容不能覆盖，需要手动在mongodb透视表里删除。

### 5. urls 范围变化会引起数据库内容变化。
后来发现总数没有变，都是196个。手动查了一下，应该是可以一一对应，我觉得应该是多进程顺序的问题。

### 最后也还是没搞明白简书网首页的url怎么构造，怂了，选的是30日h或7日的。首页等学了selenium和别的抓包方法再来继续搞。

